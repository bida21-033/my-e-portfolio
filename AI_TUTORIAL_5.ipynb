{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4StrDbzLRr-"
      },
      "outputs": [],
      "source": [
        "# Step 1: Setting up the environment\n",
        "# Install necessary libraries if you're not using Colab\n",
        "# !pip install pandas numpy scikit-learn\n",
        "\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the dataset\n",
        "data = pd.read_csv('churn_prediction.csv')\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "qR_PfJXONU_m",
        "outputId": "01e7e4df-f293-4ee5-bf8b-db1215ef48fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   customer_id  vintage  age gender  dependents     occupation    city  \\\n",
              "0            1     3135   66   Male         0.0  self_employed   187.0   \n",
              "1            2      310   35   Male         0.0  self_employed     NaN   \n",
              "2            4     2356   31   Male         0.0       salaried   146.0   \n",
              "3            5      478   90    NaN         NaN  self_employed  1020.0   \n",
              "4            6     2531   42   Male         2.0  self_employed  1494.0   \n",
              "\n",
              "   customer_nw_category  branch_code  days_since_last_transaction  ...  \\\n",
              "0                     2          755                        224.0  ...   \n",
              "1                     2         3214                         60.0  ...   \n",
              "2                     2           41                          NaN  ...   \n",
              "3                     2          582                        147.0  ...   \n",
              "4                     3          388                         58.0  ...   \n",
              "\n",
              "   previous_month_end_balance  average_monthly_balance_prevQ  \\\n",
              "0                     1458.71                        1458.71   \n",
              "1                     8704.66                        7799.26   \n",
              "2                     5815.29                        4910.17   \n",
              "3                     2291.91                        2084.54   \n",
              "4                     1401.72                        1643.31   \n",
              "\n",
              "   average_monthly_balance_prevQ2  current_month_credit  \\\n",
              "0                         1449.07                  0.20   \n",
              "1                        12419.41                  0.56   \n",
              "2                         2815.94                  0.61   \n",
              "3                         1006.54                  0.47   \n",
              "4                         1871.12                  0.33   \n",
              "\n",
              "   previous_month_credit  current_month_debit  previous_month_debit  \\\n",
              "0                   0.20                 0.20                  0.20   \n",
              "1                   0.56              5486.27                100.56   \n",
              "2                   0.61              6046.73                259.23   \n",
              "3                   0.47                 0.47               2143.33   \n",
              "4                 714.61               588.62               1538.06   \n",
              "\n",
              "   current_month_balance  previous_month_balance  churn  \n",
              "0                1458.71                 1458.71      0  \n",
              "1                6496.78                 8787.61      0  \n",
              "2                5006.28                 5070.14      0  \n",
              "3                2291.91                 1669.79      1  \n",
              "4                1157.15                 1677.16      1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52a8d44f-da82-4fbb-8f4b-fed040adb471\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>vintage</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>dependents</th>\n",
              "      <th>occupation</th>\n",
              "      <th>city</th>\n",
              "      <th>customer_nw_category</th>\n",
              "      <th>branch_code</th>\n",
              "      <th>days_since_last_transaction</th>\n",
              "      <th>...</th>\n",
              "      <th>previous_month_end_balance</th>\n",
              "      <th>average_monthly_balance_prevQ</th>\n",
              "      <th>average_monthly_balance_prevQ2</th>\n",
              "      <th>current_month_credit</th>\n",
              "      <th>previous_month_credit</th>\n",
              "      <th>current_month_debit</th>\n",
              "      <th>previous_month_debit</th>\n",
              "      <th>current_month_balance</th>\n",
              "      <th>previous_month_balance</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3135</td>\n",
              "      <td>66</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>self_employed</td>\n",
              "      <td>187.0</td>\n",
              "      <td>2</td>\n",
              "      <td>755</td>\n",
              "      <td>224.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1458.71</td>\n",
              "      <td>1458.71</td>\n",
              "      <td>1449.07</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1458.71</td>\n",
              "      <td>1458.71</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>310</td>\n",
              "      <td>35</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>self_employed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>3214</td>\n",
              "      <td>60.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8704.66</td>\n",
              "      <td>7799.26</td>\n",
              "      <td>12419.41</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.56</td>\n",
              "      <td>5486.27</td>\n",
              "      <td>100.56</td>\n",
              "      <td>6496.78</td>\n",
              "      <td>8787.61</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>2356</td>\n",
              "      <td>31</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>salaried</td>\n",
              "      <td>146.0</td>\n",
              "      <td>2</td>\n",
              "      <td>41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>5815.29</td>\n",
              "      <td>4910.17</td>\n",
              "      <td>2815.94</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.61</td>\n",
              "      <td>6046.73</td>\n",
              "      <td>259.23</td>\n",
              "      <td>5006.28</td>\n",
              "      <td>5070.14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>478</td>\n",
              "      <td>90</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>self_employed</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>2</td>\n",
              "      <td>582</td>\n",
              "      <td>147.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2291.91</td>\n",
              "      <td>2084.54</td>\n",
              "      <td>1006.54</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.47</td>\n",
              "      <td>2143.33</td>\n",
              "      <td>2291.91</td>\n",
              "      <td>1669.79</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>2531</td>\n",
              "      <td>42</td>\n",
              "      <td>Male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>self_employed</td>\n",
              "      <td>1494.0</td>\n",
              "      <td>3</td>\n",
              "      <td>388</td>\n",
              "      <td>58.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1401.72</td>\n",
              "      <td>1643.31</td>\n",
              "      <td>1871.12</td>\n",
              "      <td>0.33</td>\n",
              "      <td>714.61</td>\n",
              "      <td>588.62</td>\n",
              "      <td>1538.06</td>\n",
              "      <td>1157.15</td>\n",
              "      <td>1677.16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52a8d44f-da82-4fbb-8f4b-fed040adb471')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-52a8d44f-da82-4fbb-8f4b-fed040adb471 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-52a8d44f-da82-4fbb-8f4b-fed040adb471');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-960d3103-24ac-4276-9475-eabe10f275cc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-960d3103-24ac-4276-9475-eabe10f275cc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-960d3103-24ac-4276-9475-eabe10f275cc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Handling Missing Data\n",
        "# Check for missing values\n",
        "missing_values = data.isnull().sum() # Changed 'df' to 'data'\n",
        "print(\"Missing Values:\\n\", missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6PKBUL2N_zn",
        "outputId": "8d15a8aa-b136-47a3-b97b-cf54aa76ef71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values:\n",
            " customer_id                          0\n",
            "vintage                              0\n",
            "age                                  0\n",
            "gender                             525\n",
            "dependents                        2463\n",
            "occupation                          80\n",
            "city                               803\n",
            "customer_nw_category                 0\n",
            "branch_code                          0\n",
            "days_since_last_transaction       3223\n",
            "current_balance                      0\n",
            "previous_month_end_balance           0\n",
            "average_monthly_balance_prevQ        0\n",
            "average_monthly_balance_prevQ2       0\n",
            "current_month_credit                 0\n",
            "previous_month_credit                0\n",
            "current_month_debit                  0\n",
            "previous_month_debit                 0\n",
            "current_month_balance                0\n",
            "previous_month_balance               0\n",
            "churn                                0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can either drop rows with missing values or fill them\n",
        "# Let's fill missing numerical values with median and categorical with mode\n",
        "data.fillna(data.median(numeric_only=True), inplace=True)  # Changed 'df' to 'data'\n",
        "for column in data.select_dtypes(include=['object']).columns:  # Changed 'df' to 'data'\n",
        "    data[column].fillna(data[column].mode()[0], inplace=True)  # Changed 'df' to 'data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_YBMxAJOq27",
        "outputId": "2ee8f999-7d2c-4189-fff4-bde25e3e0644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-90ba94677152>:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data[column].fillna(data[column].mode()[0], inplace=True)  # Changed 'df' to 'data'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Encoding Categorical Variables\n",
        "# Identify categorical columns\n",
        "categorical_cols = data.select_dtypes(include=['object']).columns # Changed 'df' to 'data'"
      ],
      "metadata": {
        "id": "WNGhtsZJPQeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Apply Label Encoding for binary variables\n",
        "label_encoder = LabelEncoder()\n",
        "for col in categorical_cols:\n",
        "    if data[col].nunique() == 2:  # Binary categorical variables # Changed 'df' to 'data'\n",
        "        data[col] = label_encoder.fit_transform(data[col]) # Changed 'df' to 'data'\n",
        "    else:  # One-Hot Encoding for multiple categories\n",
        "        data = pd.get_dummies(data, columns=[col], drop_first=True) # Changed 'df' to 'data'"
      ],
      "metadata": {
        "id": "P26P-zTKPefq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Feature Scaling\n",
        "# Apply Standardization (mean=0, std=1) for numerical features\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns # Changed 'df' to 'data'\n",
        "data[numerical_cols] = scaler.fit_transform(data[numerical_cols]) # Changed 'df' to 'data'"
      ],
      "metadata": {
        "id": "cPX27LTYP5SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Encoding Categorical Variables\n",
        "# Identify categorical columns\n",
        "categorical_cols = data.select_dtypes(include=['object']).columns # Changed 'df' to 'data'\n",
        "\n",
        "# Apply Label Encoding for binary variables\n",
        "label_encoder = LabelEncoder()\n",
        "# Create a copy of categorical_cols to iterate over\n",
        "# This prevents issues when the original list is modified by get_dummies\n",
        "for col in list(categorical_cols):\n",
        "    if data[col].nunique() == 2:  # Binary categorical variables # Changed 'df' to 'data'\n",
        "        data[col] = label_encoder.fit_transform(data[col]) # Changed 'df' to 'data'\n",
        "    else:  # One-Hot Encoding for multiple categories\n",
        "        data = pd.get_dummies(data, columns=[col], drop_first=True) # Changed 'df' to 'data'"
      ],
      "metadata": {
        "id": "UdOpZd0mQEBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_encoded_col = next((col for col in data.columns if 'Churn' in col), None)\n",
        "\n",
        "# Check if churn_encoded_col was found\n",
        "if churn_encoded_col:\n",
        "    # Proceed with your logic using churn_encoded_col\n",
        "    print(f\"Churn column found: {churn_encoded_col}\")\n",
        "else:\n",
        "    # Handle the case where 'Churn' is not found in any column\n",
        "    print(\"Error: No column containing 'Churn' was found in the DataFrame.\")\n",
        "    # You can add further error handling or alternative logic here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWGnHcnlQzv-",
        "outputId": "ef9d57f2-5970-4528-b505-9b67e2ed469d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: No column containing 'Churn' was found in the DataFrame.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Splitting the data into Training and Testing Sets\n",
        "\n",
        "# Define the target variable (Churn) and feature set\n",
        "# Let's first ensure we find the correct column for the churn target (assuming the column name contains 'Churn')\n",
        "churn_encoded_col = next((col for col in data.columns if 'Churn' in col), None) # Changed 'df' to 'data'"
      ],
      "metadata": {
        "id": "Jf75aNmHSI_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Splitting the data into Training and Testing Sets\n",
        "\n",
        "# Define the target variable (Churn) and feature set\n",
        "# Assume the column name contains 'Churn' after encoding\n",
        "churn_encoded_col = next((col for col in data.columns if 'Churn' in col), None)\n",
        "\n",
        "# Check if churn column is found\n",
        "if churn_encoded_col:\n",
        "    # Separate target variable and features\n",
        "    X = data.drop(columns=[churn_encoded_col])  # Features (all columns except churn)\n",
        "    y = data[churn_encoded_col]  # Target (Churn)\n",
        "    print(f\"Churn column found: {churn_encoded_col}\")\n",
        "else:\n",
        "    # If 'Churn' is not found directly, check for encoded columns (e.g., 'Churn_Yes')\n",
        "    # Updated logic to find columns starting with 'Churn_'\n",
        "    churn_encoded_cols = [col for col in data.columns if col.startswith('Churn_')]\n",
        "    if churn_encoded_cols:\n",
        "        # Assuming the first column starting with 'Churn_' is the target\n",
        "        churn_encoded_col = churn_encoded_cols[0]\n",
        "        # Separate target variable and features using the encoded column\n",
        "        X = data.drop(columns=[churn_encoded_col])  # Features (all columns except churn)\n",
        "        y = data[churn_encoded_col]  # Target (Churn)\n",
        "        print(f\"Churn column found (encoded): {churn_encoded_col}\")\n",
        "    else:\n",
        "        print(\"Error: No column containing 'Churn' was found in the DataFrame.\")\n",
        "        print(f\"Available columns: {data.columns.tolist()}\")\n",
        "        # Handle this case if needed (e.g., raise an exception or stop execution)\n",
        "        # raise ValueError(\"Churn column not found!\")  # Consider removing or handling differently\n",
        "        # For example, you could try to identify the Churn column manually:\n",
        "        possible_churn_cols = [col for col in data.columns if 'churn' in col.lower()]\n",
        "        if possible_churn_cols:\n",
        "            print(f\"Possible Churn columns (case-insensitive): {possible_churn_cols}\")\n",
        "            # You could then ask the user to select the correct column or make an assumption\n",
        "            churn_encoded_col = possible_churn_cols[0]  # Assuming the first one is correct\n",
        "            X = data.drop(columns=[churn_encoded_col])\n",
        "            y = data[churn_encoded_col]\n",
        "        else:\n",
        "            raise ValueError(\"Churn column not found!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zkyo2oFSU4d",
        "outputId": "5f7a6422-9801-4228-984f-48d788dd82f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: No column containing 'Churn' was found in the DataFrame.\n",
            "Available columns: ['customer_id', 'vintage', 'age', 'gender', 'dependents', 'city', 'customer_nw_category', 'branch_code', 'days_since_last_transaction', 'current_balance', 'previous_month_end_balance', 'average_monthly_balance_prevQ', 'average_monthly_balance_prevQ2', 'current_month_credit', 'previous_month_credit', 'current_month_debit', 'previous_month_debit', 'current_month_balance', 'previous_month_balance', 'churn', 'occupation_retired', 'occupation_salaried', 'occupation_self_employed', 'occupation_student']\n",
            "Possible Churn columns (case-insensitive): ['churn']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Now split the data into training (80%) and testing (20%) sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "OTfm6vMBTc4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Overview of Churn Prediction\n",
        "# Here we are applying a simple machine learning model like logistic regression for churn prediction\n",
        "\n",
        "# Import Logistic Regression model\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "8UtP70iwThUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "log_reg = LogisticRegression()"
      ],
      "metadata": {
        "id": "0N1572DXTl8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'y' is your original continuous target variable\n",
        "# Divide into 2 categories (quantiles), handle potential duplicate edges\n",
        "\n",
        "# Try qcut with duplicates='drop'\n",
        "try:\n",
        "    y_categorical = pd.qcut(y, q=2, labels=[0, 1], duplicates='drop')\n",
        "except ValueError:\n",
        "    # If duplicates='drop' fails due to too few unique bins, adjust labels:\n",
        "    # If qcut results in only one bin, use a single label\n",
        "    try:\n",
        "        y_categorical = pd.qcut(y, q=2, labels=[0], duplicates='drop')\n",
        "    except ValueError:\n",
        "        #If qcut results in 3 bins and you want to drop the duplicate to maintain 2 bins\n",
        "        # y_categorical = pd.qcut(y, q=2, labels=[0, 1], duplicates='drop')\n",
        "        print(\"Warning: qcut resulted in non-unique bins even after dropping duplicates.\")\n",
        "        #If there are still errors you may need to adjust qcut parameters or further investigate data\n",
        "        print(\"Consider adjusting the 'q' parameter in qcut or further investigate data for issues.\")\n",
        "        #Fallback to assign all values to a single category if qcut continues to fail:\n",
        "        y_categorical = pd.Series(0, index=y.index, name=y.name)"
      ],
      "metadata": {
        "id": "A6UDGev4TpVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'y' is your original continuous target variable\n",
        "# Divide into 2 categories (quantiles), handle potential duplicate edges\n",
        "\n",
        "# Try qcut with duplicates='raise' to explicitly identify the issue\n",
        "try:\n",
        "    y_categorical = pd.qcut(y, q=2, labels=[0, 1], duplicates='raise')\n",
        "except ValueError as e:\n",
        "    # Log the original error message for debugging\n",
        "    print(f\"Original ValueError: {e}\")\n",
        "\n",
        "    # Check unique values in the original 'y' variable\n",
        "    unique_y = y.unique()\n",
        "    print(f\"Unique values in 'y': {unique_y}\")\n",
        "\n",
        "    # Check unique values after binning, if possible\n",
        "    try:\n",
        "        binned_y = pd.qcut(y, q=2, labels=False, duplicates='drop')\n",
        "        unique_binned_y = binned_y.unique()\n",
        "        print(f\"Unique values after binning with qcut: {unique_binned_y}\")\n",
        "    except ValueError:\n",
        "        print(\"Unable to bin data with qcut for analysis.\")\n",
        "\n",
        "    # If 'y' is indeed continuous, but resulting in only one bin:\n",
        "    if len(unique_y) > 1:\n",
        "        print(\"Warning: 'y' appears continuous but results in only one category when using qcut.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A0ENlCyUxCN",
        "outputId": "19c95278-cfb6-4230-d5b8-c116407fc8bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original ValueError: Bin edges must be unique: Index([-0.47695803960333255, -0.47695803960333255, 2.0966204927202003], dtype='float64', name='churn').\n",
            "You can drop duplicate edges by setting the 'duplicates' kwarg\n",
            "Unique values in 'y': [-0.47695804  2.09662049]\n",
            "Unique values after binning with qcut: [0]\n",
            "Warning: 'y' appears continuous but results in only one category when using qcut.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ... (Your existing code to load and prepare data) ...\n",
        "\n",
        "# Assuming 'y' is your original continuous target variable\n",
        "# Divide into 2 categories (quantiles), handle potential duplicate edges\n",
        "\n",
        "# Try qcut with duplicates='drop'\n",
        "try:\n",
        "    y_categorical = pd.qcut(y, q=2, labels=[0, 1], duplicates='drop')\n",
        "except ValueError:\n",
        "    # If duplicates='drop' fails due to too few unique bins, adjust labels:\n",
        "    # If qcut results in only one bin, use a single label\n",
        "    try:\n",
        "        y_categorical = pd.qcut(y, q=2, labels=[0], duplicates='drop')\n",
        "    except ValueError:\n",
        "        #If qcut results in 3 bins and you want to drop the duplicate to maintain 2 bins\n",
        "        # y_categorical = pd.qcut(y, q=2, labels=[0, 1], duplicates='drop')\n",
        "        print(\"Warning: qcut resulted in non-unique bins even after dropping duplicates.\")\n",
        "        #If there are still errors you may need to adjust qcut parameters or further investigate data\n",
        "        print(\"Consider adjusting the 'q' parameter in qcut or further investigate data for issues.\")\n",
        "        #Fallback to assign all values to a single category if qcut continues to fail:\n",
        "        y_categorical = pd.Series(0, index=y.index, name=y.name)\n",
        "\n",
        "#Check if y_categorical has only one unique value\n",
        "if len(y_categorical.unique()) < 2:\n",
        "    print(\"Warning: y_categorical has only one unique value. Logistic Regression requires at least two classes.\")\n",
        "    # Investigate why y_categorical has only one unique value and adjust data processing accordingly.\n",
        "    # This might involve adjusting the qcut parameters or handling class imbalance.\n",
        "    # Example: If data is imbalanced, you might consider oversampling or undersampling techniques.\n",
        "else:\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.25, random_state=16)\n",
        "\n",
        "    # Initialize the model\n",
        "    log_reg = LogisticRegression()\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    log_reg.fit(X_train, y_train)\n",
        "\n",
        "    # Step 8: Predict on the test set\n",
        "    # Now let's make predictions using the test data\n",
        "    y_pred = log_reg.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYPkEfeZVtKd",
        "outputId": "73a33e23-ec3c-4e60-de7a-f9ede86add1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: y_categorical has only one unique value. Logistic Regression requires at least two classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 9: Model Evaluation\n",
        "# Evaluate the model's performance using common classification metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ],
      "metadata": {
        "id": "fc1QuX2IWN0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# ... (Your existing code to load and prepare data) ...\n",
        "\n",
        "# Assuming 'y' is your original continuous target variable\n",
        "# Divide into 2 categories (quantiles), handle potential duplicate edges\n",
        "\n",
        "# Try qcut with duplicates='drop'\n",
        "try:\n",
        "    y_categorical = pd.qcut(y, q=2, labels=[0, 1], duplicates='drop')\n",
        "except ValueError:\n",
        "    # If duplicates='drop' fails due to too few unique bins, adjust labels:\n",
        "    # If qcut results in only one bin, use a single label\n",
        "    try:\n",
        "        y_categorical = pd.qcut(y, q=2, labels=[0], duplicates='drop')\n",
        "    except ValueError:\n",
        "        #If qcut results in 3 bins and you want to drop the duplicate to maintain 2 bins\n",
        "        # y_categorical = pd.qcut(y, q=2, labels=[0, 1], duplicates='drop')\n",
        "        print(\"Warning: qcut resulted in non-unique bins even after dropping duplicates.\")\n",
        "        #If there are still errors you may need to adjust qcut parameters or further investigate data\n",
        "        print(\"Consider adjusting the 'q' parameter in qcut or further investigate data for issues.\")\n",
        "        #Fallback to assign all values to a single category if qcut continues to fail:\n",
        "        y_categorical = pd.Series(0, index=y.index, name=y.name)\n",
        "\n",
        "#Check if y_categorical has only one unique value\n",
        "if len(y_categorical.unique()) < 2:\n",
        "    print(\"Warning: y_categorical has only one unique value. Logistic Regression requires at least two classes.\")\n",
        "    print(\"Investigate why y_categorical has only one unique value and adjust data processing accordingly.\")\n",
        "    print(\"This might involve adjusting the qcut parameters or handling class imbalance.\")\n",
        "    print(\"Example: If data is imbalanced, you might consider oversampling or undersampling techniques.\")\n",
        "    # Here you could potentially:\n",
        "    # 1. Adjust the `q` parameter in `pd.qcut`\n",
        "    # 2. Implement oversampling or undersampling to address class imbalance\n",
        "    # 3. If the target variable has no variability, consider if a classification model is appropriate\n",
        "    # For now, we'll skip model training and evaluation\n",
        "else:\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.25, random_state=16)\n",
        "\n",
        "    # Initialize the model\n",
        "    log_reg = LogisticRegression()\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    log_reg.fit(X_train, y_train)\n",
        "\n",
        "    # Step 8: Predict on the test set\n",
        "    # Now let's make predictions using the test data\n",
        "    y_pred = log_reg.predict(X_test)\n",
        "\n",
        "    # Step 9: Model Evaluation\n",
        "    # Evaluate the model's performance using common classification metrics\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcS0K8iUWSsK",
        "outputId": "7a369fa2-7143-4b33-a6ff-d3e0f103d879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: y_categorical has only one unique value. Logistic Regression requires at least two classes.\n",
            "Investigate why y_categorical has only one unique value and adjust data processing accordingly.\n",
            "This might involve adjusting the qcut parameters or handling class imbalance.\n",
            "Example: If data is imbalanced, you might consider oversampling or undersampling techniques.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# ... (Your existing code to load and prepare data) ...\n",
        "\n",
        "# Assuming 'y' is your original continuous target variable\n",
        "# Divide into 2 categories (quantiles), handle potential duplicate edges\n",
        "\n",
        "# Try qcut with duplicates='drop'\n",
        "try:\n",
        "    y_categorical = pd.qcut(y, q=2, labels=[0, 1], duplicates='drop')\n",
        "except ValueError:\n",
        "    # If duplicates='drop' fails due to too few unique bins, adjust labels:\n",
        "    # If qcut results in only one bin, use a single label\n",
        "    try:\n",
        "        y_categorical = pd.qcut(y, q=2, labels=[0], duplicates='drop')\n",
        "    except ValueError:\n",
        "        #If qcut results in 3 bins and you want to drop the duplicate to maintain 2 bins\n",
        "        # y_categorical = pd.qcut(y, q=2, labels=[0, 1], duplicates='drop')\n",
        "        print(\"Warning: qcut resulted in non-unique bins even after dropping duplicates.\")\n",
        "        #If there are still errors you may need to adjust qcut parameters or further investigate data\n",
        "        print(\"Consider adjusting the 'q' parameter in qcut or further investigate data for issues.\")\n",
        "        #Fallback to assign all values to a single category if qcut continues to fail:\n",
        "        y_categorical = pd.Series(0, index=y.index, name=y.name)\n",
        "\n",
        "#Check if y_categorical has only one unique value\n",
        "if len(y_categorical.unique()) < 2:\n",
        "    print(\"Warning: y_categorical has only one unique value. Logistic Regression requires at least two classes.\")\n",
        "    print(\"Investigate why y_categorical has only one unique value and adjust data processing accordingly.\")\n",
        "    print(\"This might involve adjusting the qcut parameters or handling class imbalance.\")\n",
        "    print(\"Example: If data is imbalanced, you might consider oversampling or undersampling techniques.\")\n",
        "    # Here you could potentially:\n",
        "    # 1. Adjust the `q` parameter in `pd.qcut`\n",
        "    # 2. Implement oversampling or undersampling to address class imbalance\n",
        "    # 3. If the target variable has no variability, consider if a classification model is appropriate\n",
        "    # For now, we'll skip model training and evaluation\n",
        "    # Initialize evaluation metrics to None to avoid NameError\n",
        "    accuracy = None\n",
        "    precision = None\n",
        "    recall = None\n",
        "    f1 = None\n",
        "else:\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.25, random_state=16)\n",
        "\n",
        "    # Initialize the model\n",
        "    log_reg = LogisticRegression()\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    log_reg.fit(X_train, y_train)\n",
        "\n",
        "    # Step 8: Predict on the test set\n",
        "    # Now let's make predictions using the test data\n",
        "    y_pred = log_reg.predict(X_test)\n",
        "\n",
        "    # Step 9: Model Evaluation\n",
        "    # Evaluate the model's performance using common classification metrics\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "```python\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# ... (Your existing code to load and prepare data) ...\n",
        "\n",
        "# Assuming 'y' is your original continuous target variable\n",
        "# Divide into 2 categories (quantiles), handle potential duplicate edges\n",
        "\n",
        "# Try qcut with duplicates='drop'\n",
        "try:\n",
        "    y_categorical = pd.qcut(y, q=2, labels=[0, 1], duplicates='drop')\n",
        "except ValueError:\n",
        "    # If duplicates='drop' fails due to too few unique bins, adjust labels:\n",
        "    # If qcut results in only one bin, use a single label\n",
        "    try:\n",
        "        y_categorical = pd.qcut(y, q=2, labels=[0], duplicates='drop')\n",
        "    except ValueError:\n",
        "        #If qcut results in 3 bins and you want to drop the duplicate to maintain 2 bins\n",
        "        # y_categorical = pd.qcut(y, q=2, labels=[0, 1], duplicates='drop')\n",
        "        print(\"Warning: qcut resulted in non-unique bins even after dropping duplicates.\")\n",
        "        #If there are still errors you may need to adjust qcut parameters or further investigate data\n",
        "        print(\"Consider adjusting the 'q' parameter in qcut or further investigate data for issues.\")\n",
        "        #Fallback to assign all values to a single category if qcut continues to fail:\n",
        "        y_categorical = pd.Series(0, index=y.index, name=y.name)\n",
        "\n",
        "#Check if y_categorical has only one unique value\n",
        "if len(y_categorical.unique()) < 2:\n",
        "    print(\"Warning: y_categorical has only one unique value. Logistic Regression requires at least two classes.\")\n",
        "    print(\"Investigate why y_categorical has only one unique value and adjust data processing accordingly.\")\n",
        "    print(\"This might involve adjusting the qcut parameters or handling class imbalance.\")\n",
        "    print(\"Example: If data is imbalanced, you might consider oversampling or undersampling techniques.\")\n",
        "    # Here you could potentially:\n",
        "    # 1. Adjust the `q` parameter in `pd.qcut`\n",
        "    # 2. Implement oversampling or undersampling to address class imbalance\n",
        "    # 3. If the target variable has no variability, consider if a classification model is appropriate\n",
        "    # For now, we'll skip model training and evaluation\n",
        "    # Initialize evaluation metrics to None to avoid NameError\n",
        "    accuracy = None\n",
        "    precision = None\n",
        "    recall = None\n",
        "    f1 = None\n",
        "else:\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.25, random_state=16)\n",
        "\n",
        "    # Initialize the model\n",
        "    log_reg = LogisticRegression()\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    log_reg.fit(X_train, y_train)\n",
        "\n",
        "    # Step 8: Predict on the test set\n",
        "    # Now let's make predictions using the test data\n",
        "    y_pred = log_reg.predict(X_test)\n",
        "\n",
        "    # Step 9: Model Evaluation\n",
        "    # Evaluate the model's performance using common classification metrics\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "1UR4IdlXWpHi",
        "outputId": "d7ade99d-0e09-4bbe-b6ac-d72bb43aa6cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-57-29a7bae324c1>, line 63)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-57-29a7bae324c1>\"\u001b[0;36m, line \u001b[0;32m63\u001b[0m\n\u001b[0;31m    ```python\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}